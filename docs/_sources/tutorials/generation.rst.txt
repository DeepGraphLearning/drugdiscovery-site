Molecule Generation
===================

.. include:: ../bibliography.rst

Molecular graph generation is a fundamental problem for drug discovery and
has been attracting growing attention. 
The problem is challenging since it requires
not only generating chemically valid molecular structures but also optimizing
their chemical properties in the meantime.

In this tutorial, we will implement two graph generative models `GCPN`_ and `GraphAF`_.
We first pretrain both models on `ZINC250k`_ dataset. 
Starting from the pretrained checkpoint, we finetune both models with reinforcement learning to optimize two properties (i.e., QED and penalized logP score) of generated molecules.


Prepare the Pretraining Dataset
-------------------------------

We use `ZINC250k`_ dataset for pretraining. The dataset contains
250,000 drug-like molecules with a maximum atom number of 38. It has 9 atom types and 3 edge
types.

First, let's donwload, load, and preprocess the dataset, which takes about 3-5 minutes.
You are encouraged to dump the preprocessed dataset to save the time for future use.

.. code:: python

    import torch
    from drugdiscovery import datasets

    dataset = datasets.ZINC250k("~/molecule-datasets/", 
                                kekulize=True, 
                                node_feature="symbol")
    # with open("path_to_dump/zinc250k.pkl", "wb") as fout:
    #     pickle.dump(dataset, fout)
    # with open("path_to_dump/zinc250k.pkl", "rb") as fin:
    #     dataset = pickle.load(fin)



Define the Model: GCPN
----------------------

The model consists of two parts, a graph representation model
and a graph generative module. 
We define a Relational Graph Convolutional Networks (`RGCN`_) as our representation model. 
We define a module called `GCPNGeneration` as the graph generative module fpr GCPN.


.. code:: python

    from drugdiscovery import core, models, tasks

    model = models.RGCN(input_dim=dataset.node_feature_dim, 
                        num_relation=dataset.num_bond_type,
                        hidden_dims = [256, 256, 256, 256], 
                        batch_norm = False)
    task = tasks.GCPNGeneration(model, dataset.atom_types, 
                                max_edge_unroll=12, max_node=38, 
                                criterion = {"nll":  1.0})
            

Pretraining and Generation: GCPN
--------------------------------

Now we can train our model. We setup an optimizer for our model, and put
everything together into an Engine instance. 
Here we only train the model for 1 epoch, and then save the pretrained model into a directory.

.. code:: python

    from torch import nn, optim
    optimizer = optim.Adam(task.parameters(), lr = 1e-3)
    solver = core.Engine(task, dataset, None, None, optimizer, 
                         gpus = (0,),
                         batch_size = 128,
                         log_interval = 10)

    solver.train(num_epoch=1)
    solver.save("path_to_dump/graphgeneration/gcpn_zinc250k_1epoch.pkl")

During the pretraining procedure, we may obtain some logs as follows, which report the accuracy of action predictions.

.. code:: bash

    edge acc: 0.896366
    edge loss: 0.234644
    node1 acc: 0.596209
    node1 loss: 1.04997
    node2 acc: 0.747235
    node2 loss: 0.723717
    stop acc: 0.849681
    stop bce loss: 0.247942
    total loss: 2.25627

After the model is pretrained, we can load the parameters from the checkpoint as follows.
Let's generate some small molecules from the pretrained GCPN model.

.. code:: python

    from collections import defaultdict

    solver.load("path_to_dump/graphgeneration/gcpn_zinc250k_1epoch.pkl")
    optimizer.state = defaultdict(dict)
    task = task.cuda()
    results = task.generate(num_sample=32, max_resample=5)
    print(results.to_smiles())

The results are as follows:

.. code:: bash

    C=S(C)CC(=O)NC(CCN)CCCC
    CCN(C)C1(C2NC2=O)CCCC1C
    CC1=CC=CC=C1C(=O)N1CC1CS
    CN=NC1=NC=CC2=CC=C(C=C2)CCNC(=O)C1
    CC(CC(=O)NC1=CC=C(N)C2=CC=CC=C12)C1=CC=CC=C1
    ...

Let’s visualize some generated molecules.

.. image:: ../../../asset/dataset/clintox.png


Goal-Directed Molecule Generation with Reinforcement Learning: GCPN
-------------------------------------------------------------------

For drug discovery, we need to optimize the chemical properties of generated molecules. 
In this part, we introduce how to fine-tune the graph generative model with reinforcement learning to optimize the properties of generated molecules.
We implemented the Proximal Policy Optimization (PPO) algorithm for both GCPN and GraphAF.
To finetune the pretrained model with reinforcement learning, we only need to modify several lines of code in the task initialization.
We provide all the codes for finetuning in the following segment.

For Penalized logP optimization, the code is as follows:

.. code:: python

    import torch
    from drugdiscovery import datasets
    from drugdiscovery import core, models, tasks
    from torch import nn, optim
    from collections import defaultdict

    dataset = datasets.ZINC250k("~/molecule-datasets/", 
                                kekulize=True, 
                                node_feature="symbol")    

    model = models.RGCN(input_dim=dataset.node_feature_dim, 
                        num_relation=dataset.num_bond_type,
                        hidden_dims = [256, 256, 256, 256], 
                        batch_norm = False)
    task = tasks.GCPNGeneration(model, dataset.atom_types, 
                                max_edge_unroll=12, max_node=38, 
                                reward_temperature = 1,
                                task = "plogp",
                                criterion = {"ppo":  1.0},
                                agent_update_interval = 3,
                                gamma = 0.90)


    optimizer = optim.Adam(task.parameters(), lr = 1e-5)
    solver = core.Engine(task, dataset, None, None, optimizer, 
                         gpus = (0,),
                         batch_size = 16,
                         log_interval = 10)

    solver.load("path_to_dump/graphgeneration/gcpn_zinc250k_1epoch.pkl")
    optimizer.state = defaultdict(dict)                         

    #rl finetuning
    solver.train(num_epoch=10)
    solver.save("path_to_dump/graphgeneration/gcpn_zinc250k_1epoch_finetune.pkl")    

                             
The results are as follows:

.. code:: bash

    (6.56, 'CCCCC(CCC)(CCCC)C(C)C(C)(CCC)C(CCC)(CCC)C(C)(C(C)C)C(C)(C)CCCC')
    (6.46, 'CCCCC(CCC(C)C)(C(CC)(CCC)C(C)(C)CCC)C(CC(C)C)(CC(C)C)C(C)(C)C(C)(C)C')
    (6.40, 'CCCC(CCC)CC(C)(C(C)(C)C(C)(CC)CC)C(C)(C)C(C)(C(C)(C)CCC)C(C)(C)CCC')
    (6.18, 'CCCCC(CCC)CC(CC(C)C)C(C)(C)C(CCC)(C(C)CC)C(CCC)(CCCC)CCC(C)C')
    ...

Let’s visualize some molecules with large Penalized logP scores (> 6).

.. image:: ../../../asset/dataset/clintox.png


For QED optimization, the task initialization is as follows:

.. code:: python
    
    task = tasks.GCPNGeneration(model, dataset.atom_types, 
                                max_edge_unroll=12, max_node=38, 
                                reward_temperature = 1,
                                task = "qed",
                                criterion = {"ppo":  1.0, "nll": 1.0},
                                agent_update_interval = 3,
                                gamma = 0.90)    

The results are as follows:

.. code:: bash

    (0.948, 'C1=CC=C(CNC2=NC=NCC3=CN2C(C2=COCC2)=C3)C=C1')
    (0.948, 'CCC1=CC=CC=C1NC(=O)C12CC(=O)N(C1)C1=CC=CC=C12')
    (0.947, 'O=C1CCNC(C2=CC=CN=C2)CN1CC1=CC=CC(Cl)=C1')       
    (0.947, 'CC1=C(C(=O)NC2CCCN(C3=CC=CC=C3)C2)C=CN=C1')
    (0.947, 'CCNC1CCC2=CC=CC(=C2)N(C(=O)C2=CC=CC=N2)C1')
    (0.946, 'O=C(C1=CC=CC=C1F)N1CC2=CC=CC=C2C(CCO)C1')
    ...

Let’s visualize some molecules with large QED scores (> 0.945).

.. image:: ../../../asset/dataset/clintox.png
